---
title: "Pas besoin de ChatGPT pour ça"
authors:
  - name: "Hategekimana Vestin" 
    affiliation: "Université de Genève"
    email: "vestin.hategekimana@unige.ch"
format: 
  clean-revealjs:
    transition: slide
    logo: figure/wedata_logo.png
    auto-animate: true
  docx: default
  beamer:
    theme: "Dove"
editor: visual
---

# Présentation

## Qui suis-je?

### Vestin Hategekimana

.

![](figure/pp.jpeg){.absolute top="0" right="480" width="230"}

-   Assistant-doctorant en démographie (IDESO)

    -   Institut de socioéconomie et de démographie (UNIGE)

-   Migration et mobilité en Suisse en temps de crise

-   Passionné des sciences des données et la programmation (computational social sciences)

## WeData

![](figure/wedata_logo.png){width="100"}

> "Des stats et du code!"

*Groupe étudiant ayant une passion pour le code et les statistiques: cours et contenu!*

-   Notre site: <https://wedata.ch/>
-   Notre chaîne YouTube: [WeData](https://www.youtube.com/channel/UCGktdbvbc_H-JEkYYTvwRVw)
-   Linkedin/Instagram/Facebook: @wedata_unige

## Questions d'introduction

-   Qui êtes-vous? (nom et activité)
-   Votre expérience avec l'IA?
-   Que pensez-vous de l'IA?
-   Pourquoi avoir choisi ce cours?

## Pour ce cours

::: callout-note
Pour le bon déroulement du cours, sachez que:

1.  Je suis un amateur passionné

2.  C'est la première fois que j'enseigne le sujet

3.  Ce n'est pas un cours formel

4.  Vous pouvez partir à n'importe quel moment

5.  Vous pouvez m'interrompre si vous avez une question
:::

## Objectifs du cours :

-   Acquérir un vocabulaire propre au domaine des LLMs (Large Language Models)
-   Comprendre les limitations des grands modèles comme ChatGPT et leurs alternatives
-   Comprendre les avantages des modèles locaux
-   Savoir utiliser les modèles locaux (installation, system prompt, RAG, huggingface, etc.)

## Plan du cours

-   Qu'est-ce que ChatGPT ? (30 minutes)

-   Alternatives Viables ? (35 minutes)

-   Ollama et compagnie (20 minutes)

-   Ollama pratique (90 minutes)

# Avant de commencer, téléchargeons Ollama!

## Lien vers Ollama

### https://ollama.com/

# Qu'est-ce que ChatGPT ? (30 minutes)

## À quoi ressemble ChatGPT? {auto-animate="true"}

À ça?

[![Écran d'accueil de ChatGPT](figure/chatgpt_intro_screen.webp){fig-align="center"}](https://www.google.com/url?sa=i&url=https%3A%2F%2Fedunow.me%2Ftechnology%2Fwhat-is-chatgpt-google-search-the-beginning-of-the-end%2F&psig=AOvVaw2CpVpSHTK5Ew6-rZyFNB6T&ust=1739142622038000&source=images&cd=vfe&opi=89978449&ved=0CBQQjRxqFwoTCNjktaaZtYsDFQAAAAAdAAAAABAE)

## À quoi ressemble ChatGPT? {auto-animate="true"}

Probablement à ça...

![Illustration de severs](figure/Microsoft-Windows-Server-2025-kommt.jpg){fig-align="center"}

## Qu'est-ce que l'intelligence artificielle (IA) ? {auto-animate="true"}

::: {layout-ncol="2"}
[![](figure/chatgpt_election.PNG){width="400"}](https://www.bfmtv.com/tech/intelligence-artificielle/chat-gpt-est-aussi-utilise-pour-tenter-d-influencer-les-elections_AV-202410100528.html)

[![](figure/tesla_musk_1.PNG){width="1105"}](https://www.leparisien.fr/high-tech/sans-volant-ni-pedales-a-quoi-ressemble-le-robotaxi-de-tesla-presente-par-musk-11-10-2024-5HC7HOVIAJGALBQBZMINTVLG6U.php)

[![](figure/prix_nobel_physique.PNG){width="1575"}](https://www.francetvinfo.fr/internet/intelligence-artificielle/prix-nobel-de-physique-nous-n-avons-jamais-cotoye-quelque-chose-de-plus-intelligent-que-nous-s-inquiete-le-laureat-geoffrey-hinton_6827603.html)

[![](figure/ia_remplacement.PNG){width="838"}](https://www.lebigdata.fr/enquete-ia-impact-emploi)
:::

## Qu'est-ce que l'intelligence artificielle (IA) ? {auto-animate="true"}

-   **Définition simple** : L'IA est un modèle informatique ayant pour but **d'imiter l'intelligence humaine**.
-   Il existe différents types d'IA, allant de **l'IA étroite** (spécialisée dans une tâche spécifique) à **l'IA générale** (capable d'effectuer n'importe quelle tâche intellectuelle humaine), bien que cette dernière reste encore théorique.

[![](figure/brain_ai.jpg){fig-align="center" width="450"}](https://www.google.com/url?sa=i&url=https%3A%2F%2Fincubator.ucf.edu%2Fwhat-is-artificial-intelligence-ai-and-why-people-should-learn-about-it%2F&psig=AOvVaw3esR4J2xLdtEc3Ngn-TxqW&ust=1728757950712000&source=images&cd=vfe&opi=89978449&ved=0CBcQjhxqFwoTCOjrrbP7hokDFQAAAAAdAAAAABAE)

## Top des companies dans l'IA generative

1.  **OpenAI** : ChatGPT (GPT-3.5, GPT-4, GPT-4o, o1, o3), Dall-E, Sora
2.  **Google** : PaLM, Bard, Gemini, Gemma, Imagen
3.  **Meta** : Llama (2, 3, 3.1, 3.2), codeLlama
4.  **Anthropic** : Claude (2, 3 haiku, 3 sonnet, 3 opus, 3.5 sonnet)
5.  **Microsoft** : Bing AI, Copilot, GitHub Copilot

[![](figure/ai_leadin_company.png){fig-align="center" width="599"}](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.thinkers360.com%2F50-thought-leading-companies-on-artificial-intelligence-2023%2F&psig=AOvVaw2cerBJcmJB3GxVpoZTPF38&ust=1728758206562000&source=images&cd=vfe&opi=89978449&ved=0CBcQjhxqFwoTCMiOnq78hokDFQAAAAAdAAAAABAE)

# Avant de continuer, installons Qwen2.5!

## Ouvrez le terminal!

[Tuto Widows](https://lecrabeinfo.net/tutoriels/ouvrir-et-utiliser-le-terminal-windows-sur-windows-11-10/)

[Tuto Mac](https://support.apple.com/fr-fr/guide/terminal/apd5265185d-f365-44cb-8b09-71a064a42125/mac)

Tuto linux... non c'est une blague!

## Installez Qwen2.5:3b

Lien: [Qwen2.5:3b](https://ollama.com/library/qwen2.5:3b)

Code:

```bash
ollama run qwen2.5:3b
```

## Brève histoire de l'IA

### L'IA : un vaste champ d'application

::::: columns
::: {.column width="50%"}
```{=html}
<svg width="500" xmlns="http://www.w3.org/2000/svg" height="500" id="screenshot-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" viewBox="162 124 285 286" style="-webkit-print-color-adjust::exact" xmlns:xlink="http://www.w3.org/1999/xlink" fill="none" version="1.1">
<style>
  </style>
<g id="shape-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" data-testid="Group" rx="0" ry="0"> <-- IA rectangle --> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6a72f05a74" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6a72f05a74"> <rect rx="25" ry="25" x="162" y="124" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="285" height="285" style="fill:#f354cb;fill-opacity:1"> </rect> </g> </g> <-- Machine Learning rectnagle --> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6a9b88e6a7" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6a9b88e6a7"> <rect rx="25" ry="25" x="189" y="152" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="258" height="258" style="fill:#549df3;fill-opacity:1"> </rect> </g> </g> <-- Deep Learning rectnagle --> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6ab3ff09f6" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6ab3ff09f6"> <rect rx="25" ry="25" x="217.00000000000003" y="180" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="229.99999999999994" height="230" style="fill:#48f9f9;fill-opacity:1"> </rect> </g> </g> <-- IA générative rectangle --> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6aea98cc51" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6aea98cc51"> <rect rx="25" ry="25" x="244" y="206" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="203" height="203" style="fill:#f9f748;fill-opacity:1"> </rect> </g> </g> <-- IA label --> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd" data-testid="Intelligence Artificielle"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="180" y="128" width="200" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="180" y="128" width="199.5" height="27.519996643066406" id="fill-0-render-38-0"> <g> <rect width="199.5" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd"> <text x="180" y="153.59999668598175" dominant-baseline="ideographic" textLength="199.5" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Intelligence Artificielle</text> </g> </g> </g> <-- Machine learning label --> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b6785ee98" data-testid="Machine Learning"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="200" y="156" width="157" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="200" y="156" width="156.00997924804688" height="27.519996643066406" id="fill-0-render-39-0"> <g> <rect width="156.00997924804688" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b6785ee98"> <text x="200" y="181.59999668598175" dominant-baseline="ideographic" textLength="156.00997924804688" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Machine Learning</text> </g> </g> </g> <-- Deep learning label --> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b78567d4a" data-testid="Deep Learning"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="230" y="184" width="127" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="230" y="184" width="126.89998626708984" height="27.519996643066406" id="fill-0-render-40-0"> <g> <rect width="126.89998626708984" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b78567d4a"> <text x="230" y="209.59999668598175" dominant-baseline="ideographic" textLength="126.89998626708984" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Deep Learning</text> </g> </g> </g> <-- générative IA label --> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b98a4ed79" data-testid="IA Générative"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="259" y="212" width="119" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="259" y="212" width="118.39998626708984" height="27.519996643066406" id="fill-0-render-41-0"> <g> <rect width="118.39998626708984" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b98a4ed79"> <text x="259" y="237.59999668598175" dominant-baseline="ideographic" textLength="118.39998626708984" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">IA Générative</text> </g> </g> </g> </g>

</svg>
```
:::

::: {.column width="50%"}
-   L'intelligence artificielle (IA) est le domaine général de la création de machines capables d'effectuer des tâches qui requièrent généralement l'intelligence humaine.
-   L'IA comporte plusieurs sous-domaines, dont **l'apprentissage machine (Machine Learning ou ML)** et **l'apprentissage profond (Deep Learning ou DL)**.
:::
:::::

------------------------------------------------------------------------

## L'écosystème de l'IA : Composants clés {auto-animate="true"}

::::: columns
::: {.column width="50%"}
```{=html}
<svg width="500" xmlns="http://www.w3.org/2000/svg" height="500" id="screenshot-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" viewBox="162 124 285 286" style="-webkit-print-color-adjust::exact" xmlns:xlink="http://www.w3.org/1999/xlink" fill="none" version="1.1">

<style>
  </style>

<g id="shape-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" data-testid="Group" rx="0" ry="0"> \<-- IA rectangle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6a72f05a74" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6a72f05a74"> <rect rx="25" ry="25" x="162" y="124" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="285" height="285" style="fill:#f354cb;fill-opacity:1"> </rect> </g> </g> \<-- IA label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd" data-testid="Intelligence Artificielle"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="180" y="128" width="200" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="180" y="128" width="199.5" height="27.519996643066406" id="fill-0-render-38-0"> <g> <rect width="199.5" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd"> <text x="180" y="153.59999668598175" dominant-baseline="ideographic" textLength="199.5" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Intelligence Artificielle</text> </g> </g> </g> </g>

</svg>
```
:::

::: {.column width="50%"}
1.  **Intelligence artificielle (IA)** : Le vaste domaine qui englobe toutes les capacités des "machines intelligentes".
    -   Tâches : Résolution de problèmes, perception, prise de décision.
:::
:::::

## L'écosystème de l'IA : Composants clés {auto-animate="true"}

::::: columns
::: {.column width="50%"}
```{=html}
<svg width="500" xmlns="http://www.w3.org/2000/svg" height="500" id="screenshot-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" viewBox="162 124 285 286" style="-webkit-print-color-adjust::exact" xmlns:xlink="http://www.w3.org/1999/xlink" fill="none" version="1.1">

<style>
  </style>

<g id="shape-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" data-testid="Group" rx="0" ry="0"> \<-- IA rectangle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6a72f05a74" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6a72f05a74"> <rect rx="25" ry="25" x="162" y="124" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="285" height="285" style="fill:#f354cb;fill-opacity:1"> </rect> </g> </g> \<-- Machine Learning rectnagle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6a9b88e6a7" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6a9b88e6a7"> <rect rx="25" ry="25" x="189" y="152" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="258" height="258" style="fill:#549df3;fill-opacity:1"> </rect> </g> </g> \<-- IA label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd" data-testid="Intelligence Artificielle"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="180" y="128" width="200" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="180" y="128" width="199.5" height="27.519996643066406" id="fill-0-render-38-0"> <g> <rect width="199.5" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd"> <text x="180" y="153.59999668598175" dominant-baseline="ideographic" textLength="199.5" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Intelligence Artificielle</text> </g> </g> </g> \<-- Machine learning label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b6785ee98" data-testid="Machine Learning"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="200" y="156" width="157" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="200" y="156" width="156.00997924804688" height="27.519996643066406" id="fill-0-render-39-0"> <g> <rect width="156.00997924804688" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b6785ee98"> <text x="200" y="181.59999668598175" dominant-baseline="ideographic" textLength="156.00997924804688" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Machine Learning</text> </g> </g> </g> </g>

</svg>
```
:::

::: {.column width="50%"}
2.  **Apprentissage machine (ML)** : Sous-domaine de l'IA dans lequel les machines apprennent à partir de [données]{.underline} et améliorent leurs performances au fil du temps.
    -   Exemple : Filtres anti-spam, prédiction financière ou actuarielle

[![](figure/ml_rule.png){fig-align="center"}](https://www.google.com/url?sa=i&url=https%3A%2F%2Fgithub.com%2F0liverFlow%2FHandwritingRecognition&psig=AOvVaw1NLm_iyJfurBj9aIBcJ0v3&ust=1728758701700000&source=images&cd=vfe&opi=89978449&ved=0CBcQjhxqFwoTCKC44aH-hokDFQAAAAAdAAAAABAE)
:::
:::::

## L'écosystème de l'IA : Composants clés {auto-animate="true"}

::::: columns
::: {.column width="50%"}
```{=html}
<svg width="500" xmlns="http://www.w3.org/2000/svg" height="500" id="screenshot-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" viewBox="162 124 285 286" style="-webkit-print-color-adjust::exact" xmlns:xlink="http://www.w3.org/1999/xlink" fill="none" version="1.1">

<style>
  </style>

<g id="shape-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" data-testid="Group" rx="0" ry="0"> \<-- IA rectangle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6a72f05a74" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6a72f05a74"> <rect rx="25" ry="25" x="162" y="124" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="285" height="285" style="fill:#f354cb;fill-opacity:1"> </rect> </g> </g> \<-- Machine Learning rectnagle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6a9b88e6a7" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6a9b88e6a7"> <rect rx="25" ry="25" x="189" y="152" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="258" height="258" style="fill:#549df3;fill-opacity:1"> </rect> </g> </g> \<-- Deep Learning rectnagle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6ab3ff09f6" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6ab3ff09f6"> <rect rx="25" ry="25" x="217.00000000000003" y="180" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="229.99999999999994" height="230" style="fill:#48f9f9;fill-opacity:1"> </rect> </g> </g> \<-- IA label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd" data-testid="Intelligence Artificielle"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="180" y="128" width="200" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="180" y="128" width="199.5" height="27.519996643066406" id="fill-0-render-38-0"> <g> <rect width="199.5" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd"> <text x="180" y="153.59999668598175" dominant-baseline="ideographic" textLength="199.5" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Intelligence Artificielle</text> </g> </g> </g> \<-- Machine learning label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b6785ee98" data-testid="Machine Learning"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="200" y="156" width="157" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="200" y="156" width="156.00997924804688" height="27.519996643066406" id="fill-0-render-39-0"> <g> <rect width="156.00997924804688" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b6785ee98"> <text x="200" y="181.59999668598175" dominant-baseline="ideographic" textLength="156.00997924804688" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Machine Learning</text> </g> </g> </g> \<-- Deep learning label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b78567d4a" data-testid="Deep Learning"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="230" y="184" width="127" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="230" y="184" width="126.89998626708984" height="27.519996643066406" id="fill-0-render-40-0"> <g> <rect width="126.89998626708984" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b78567d4a"> <text x="230" y="209.59999668598175" dominant-baseline="ideographic" textLength="126.89998626708984" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Deep Learning</text> </g> </g> </g> </g>

</svg>
```
:::

::: {.column width="50%"}
3.  **Apprentissage en profondeur (DL)** : Un sous-ensemble spécialisé de l'intelligence artificielle utilisant des [réseaux neuronaux]{.underline} avec de nombreuses couches pour traiter des données complexes.
    -   Exemple : systèmes de reconnaissance d'images

[![](figure/multilayer_neural_network.png){fig-align="center" width="318"}](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.geeksforgeeks.org%2Fartificial-neural-networks-and-its-applications%2F&psig=AOvVaw1-I58z59oKvtqSGWz_5B6H&ust=1728758990750000&source=images&cd=vfe&opi=89978449&ved=0CBcQjhxqFwoTCMiAiKD_hokDFQAAAAAdAAAAABAE)
:::
:::::

## L'écosystème de l'IA : Composants clés {auto-animate="true"}

::::: columns
::: {.column width="50%"}
```{=html}
<svg width="500" xmlns="http://www.w3.org/2000/svg" height="500" id="screenshot-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" viewBox="162 124 285 286" style="-webkit-print-color-adjust::exact" xmlns:xlink="http://www.w3.org/1999/xlink" fill="none" version="1.1">

<style>
  </style>

<g id="shape-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" data-testid="Group" rx="0" ry="0"> \<-- IA rectangle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6a72f05a74" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6a72f05a74"> <rect rx="25" ry="25" x="162" y="124" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="285" height="285" style="fill:#f354cb;fill-opacity:1"> </rect> </g> </g> \<-- Machine Learning rectnagle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6a9b88e6a7" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6a9b88e6a7"> <rect rx="25" ry="25" x="189" y="152" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="258" height="258" style="fill:#549df3;fill-opacity:1"> </rect> </g> </g> \<-- Deep Learning rectnagle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6ab3ff09f6" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6ab3ff09f6"> <rect rx="25" ry="25" x="217.00000000000003" y="180" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="229.99999999999994" height="230" style="fill:#48f9f9;fill-opacity:1"> </rect> </g> </g> \<-- IA générative rectangle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6aea98cc51" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6aea98cc51"> <rect rx="25" ry="25" x="244" y="206" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="203" height="203" style="fill:#f9f748;fill-opacity:1"> </rect> </g> </g> \<-- IA label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd" data-testid="Intelligence Artificielle"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="180" y="128" width="200" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="180" y="128" width="199.5" height="27.519996643066406" id="fill-0-render-38-0"> <g> <rect width="199.5" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd"> <text x="180" y="153.59999668598175" dominant-baseline="ideographic" textLength="199.5" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Intelligence Artificielle</text> </g> </g> </g> \<-- Machine learning label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b6785ee98" data-testid="Machine Learning"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="200" y="156" width="157" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="200" y="156" width="156.00997924804688" height="27.519996643066406" id="fill-0-render-39-0"> <g> <rect width="156.00997924804688" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b6785ee98"> <text x="200" y="181.59999668598175" dominant-baseline="ideographic" textLength="156.00997924804688" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Machine Learning</text> </g> </g> </g> \<-- Deep learning label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b78567d4a" data-testid="Deep Learning"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="230" y="184" width="127" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="230" y="184" width="126.89998626708984" height="27.519996643066406" id="fill-0-render-40-0"> <g> <rect width="126.89998626708984" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b78567d4a"> <text x="230" y="209.59999668598175" dominant-baseline="ideographic" textLength="126.89998626708984" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Deep Learning</text> </g> </g> </g> \<-- générative IA label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b98a4ed79" data-testid="IA Générative"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="259" y="212" width="119" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="259" y="212" width="118.39998626708984" height="27.519996643066406" id="fill-0-render-41-0"> <g> <rect width="118.39998626708984" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b98a4ed79"> <text x="259" y="237.59999668598175" dominant-baseline="ideographic" textLength="118.39998626708984" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">IA Générative</text> </g> </g> </g> </g>

</svg>
```
:::

::: {.column width="50%"}
4.  **Intelligence artificielle générative (Gen AI** ou **GAI) :** Les systèmes d'intelligence artificielle capables de [créer un contenu]{.underline} original tel que [du texte]{.underline}, [des images]{.underline}, [du son]{.underline}, [de la vidéo]{.underline} ou [du code]{.underline} en réponse à des invites ou à des demandes.
    -   Exemple : Dall-E (image), Sora (Vidéo) ou ChatGPT (Texte)
:::
:::::

------------------------------------------------------------------------

## L'écosystème de l'IA : Composants clés {auto-animate="true"}

::::: columns
::: {.column width="50%"}
```{=html}
<svg width="500" xmlns="http://www.w3.org/2000/svg" height="500" id="screenshot-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" viewBox="162 124 285 286" style="-webkit-print-color-adjust::exact" xmlns:xlink="http://www.w3.org/1999/xlink" fill="none" version="1.1">

<style>
  </style>

<g id="shape-ab84bb9a-2f00-80b7-8005-1a6e26dd9d28" data-testid="Group" rx="0" ry="0"> \<-- IA rectangle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6a72f05a74" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6a72f05a74"> <rect rx="25" ry="25" x="162" y="124" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="285" height="285" style="fill:#f354cb;fill-opacity:1"> </rect> </g> </g> \<-- Machine Learning rectnagle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6a9b88e6a7" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6a9b88e6a7"> <rect rx="25" ry="25" x="189" y="152" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="258" height="258" style="fill:#549df3;fill-opacity:1"> </rect> </g> </g> \<-- Deep Learning rectnagle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6ab3ff09f6" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6ab3ff09f6"> <rect rx="25" ry="25" x="217.00000000000003" y="180" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="229.99999999999994" height="230" style="fill:#48f9f9;fill-opacity:1"> </rect> </g> </g> \<-- IA générative rectangle --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6aea98cc51" data-testid="Rectangle"> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6aea98cc51"> <rect rx="25" ry="25" x="244" y="206" transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" width="203" height="203" style="fill:#f9f748;fill-opacity:1"> </rect> </g> </g> \<-- IA label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd" data-testid="Intelligence Artificielle"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="180" y="128" width="200" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="180" y="128" width="199.5" height="27.519996643066406" id="fill-0-render-38-0"> <g> <rect width="199.5" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b1b744cdd"> <text x="180" y="153.59999668598175" dominant-baseline="ideographic" textLength="199.5" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Intelligence Artificielle</text> </g> </g> </g> \<-- Machine learning label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b6785ee98" data-testid="Machine Learning"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="200" y="156" width="157" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="200" y="156" width="156.00997924804688" height="27.519996643066406" id="fill-0-render-39-0"> <g> <rect width="156.00997924804688" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b6785ee98"> <text x="200" y="181.59999668598175" dominant-baseline="ideographic" textLength="156.00997924804688" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Machine Learning</text> </g> </g> </g> \<-- Deep learning label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b78567d4a" data-testid="Deep Learning"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="230" y="184" width="127" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="230" y="184" width="126.89998626708984" height="27.519996643066406" id="fill-0-render-40-0"> <g> <rect width="126.89998626708984" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b78567d4a"> <text x="230" y="209.59999668598175" dominant-baseline="ideographic" textLength="126.89998626708984" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">Deep Learning</text> </g> </g> </g> \<-- générative IA label --\> <g id="shape-ab84bb9a-2f00-80b7-8005-1a6b98a4ed79" data-testid="IA Générative"> <g transform="matrix(1.000000, 0.000000, 0.000000, 1.000000, 0.000000, 0.000000)" class="text-container" x="259" y="212" width="119" height="24" rx="0" ry="0"> <defs> <pattern patternUnits="userSpaceOnUse" x="259" y="212" width="118.39998626708984" height="27.519996643066406" id="fill-0-render-41-0"> <g> <rect width="118.39998626708984" height="27.519996643066406" style="fill:#000000;fill-opacity:1"> </rect> </g> </pattern> </defs> <g class="fills" id="fills-ab84bb9a-2f00-80b7-8005-1a6b98a4ed79"> <text x="259" y="237.59999668598175" dominant-baseline="ideographic" textLength="118.39998626708984" lengthAdjust="spacingAndGlyphs" style="text-transform:none;font-family:sourcesanspro;letter-spacing:normal;font-style:normal;font-weight:700;white-space:pre;font-size:20px;text-decoration:none solid rgb(0, 0, 0);direction:ltr;fill:#000000;fill-opacity:1">IA Générative</text> </g> </g> </g> </g>

</svg>
```
:::

::: {.column width="50%"}
5.  **Large language model (LLM)** : Un sous-domaine de l'IA génératieve axé sur les tâches liées au [langage naturel (texte)]{.underline}.
    -   Tâches: [Résumé]{.underline}, [production]{.underline}, [classification]{.underline}, [traduction]{.underline} et [correction]{.underline} de texte
    -   Exemple : Modèles GPT comme ChatGPT.

[![](figure/chatgpt.png){fig-align="center" width="125"}](https://www.google.com/url?sa=i&url=https%3A%2F%2Fmetricool.com%2Fchatgpt%2F&psig=AOvVaw10vd1jOvzY2EpSNsZIgFWI&ust=1728759274327000&source=images&cd=vfe&opi=89978449&ved=0CBcQjhxqFwoTCPiMt6aAh4kDFQAAAAAdAAAAABAE)
:::
:::::

## Pour plus de détails sur l'histoire de l'intelligence artificielle

[IA assistant: méthode, pratique et éthique](https://cyuhat.github.io/ai_assistant/)

## ChatGPT c'est...

![](figure/openai-logo-freelogovectors.net_-974571776.png)

Un ensemble de modèle de OpenAI qui peut:

1. Créer et traiter du texte

2. Faire de la programmation

3. Créer et traiter des images

4. Créer et traiter du son

En bref, très puissants

## Mais il a des limites:

- Il est parfois incorrect

- Il est imprécis

- Il est consensuel

- Il est biaisé

Mais ce ne sont pas les plus grande limites!

## Les problèmes importants de ChatGPT

1. Ne respecte pas la vie privée

2. Cause des nouveaux défis environementaux

3. Pose de sérieux problèmes ethiques

## Problème de vie privée

![](figure/big-data.jpg)

- Nous vivons dans une période de bigdata

- Les grandes compagnies collectent énormément de données sur nous

- OpenAi collecte les données de conversation pour entraîner ses modèles

## Exemple de google

Comment google track nos données?

1. Historique de recherche

2. Google analytic

## Transparence de la recherche: 

![](figure/google-search.jpg)

**Nos historiques de recherches sont plus transparentes qu'on le croit**

## Un petit jeu: historique de recherche (1)

opticien neuchâtel

unil inscription

coloc lausanne

job étudiant

bourse étude

## Un petit jeu: historique de recherche (2)

tourisme suisse été

notaire liège

hotel nyon

davis cup

randonnées suisse

dépression symptômes

## Solution

Utiliser des moteurs de recherche qui garantissent la vie privée

[duckduckgo](https://duckduckgo.com/)

[brave](https://search.brave.com/)

## Problème environnemental

### Consommation d'énergie et émissions de carbone :

-   **Utilisation massive d'énergie** : Les modèles d'IA, en particulier les large language models (LLM), nécessitent une puissance de calcul importante et consomment de grandes quantités d'électricité.
-   **Empreinte carbone** : La formation de grands modèles d'IA peut émettre des centaines de tonnes de CO2. Par exemple, la formation du GPT-3 d'OpenAI a émis environ **500 tonnes de CO2**​.
-   **Croissance exponentielle** : À mesure que les modèles d'IA deviennent plus avancés, leurs besoins en énergie doublent environ tous les 3 - 4 mois​.

------------------------------------------------------------------------

### Eau et déchets électroniques:

-   **Centres de données** : Les modèles d'IA nécessitent un refroidissement important, ce qui entraîne une consommation d'eau considérable.
-   D'ici 2027, les centres de données liés à l'IA pourraient consommer **quatre fois l'utilisation annuelle d'eau du Danemark** pour le refroidissement.
-   La dépendance de l'IA à l'égard du matériel informatique contribue aux **déchets électroniques**, qui peuvent nuire à l'environnement.

[![](figure/environnement.PNG)](https://news.google.com/read/CBMi0wFBVV95cUxNVTFWZHQ2bEJvMDhqRlNGenR6SmdNNlM1cjExOHREYmM1STZjSGp2R0c2QzRKTWxsNkFoSlktekdjbjVLc0pHSUs5MEFiRE5MbEVWOW1iempCWExoRWVLeTJIRGVDbW9YZE9UeWpYUWJIcGVlRkVzLXozajdWNzNyaFJJd0dmNGx4V0FRNVQwM2w4VzNQVUtMVkVvMjdYOXFmdDQ5NlJScXdUa251U3g5MHpHc0E0SFVtbFJXcFRsRDFPX3h4TEpUakFFV01ZYm1fX2dn?hl=fr&gl=FR&ceid=FR%3Afr)

## Projet stagrate

![](figure/stargate.webp)

## Problème éthique

## L'IA et le monopole des entreprises

### Monopole du pouvoir de l'IA :

-   Le développement de l'IA est **dominé par quelques géants de la technologie** tels que OpenAI, Google, Microsoft et Amazon. **Et Nvidia!**
    -   Trop cher pour n'importe qui d'autres (infrastructure et énergie)
-   Ces entreprises contrôlent les **données, les ressources et l'infrastructure** nécessaires au développement de modèles d'IA avancés, ce qui leur confère un contrôle monopolistique.
-   Ce monopole rend la **concurrence difficile pour les petites entreprises ou les initiatives open-source**, étouffant ainsi l'innovation et la diversité dans ce domaine.
    -   Ces initiatives existent tout de même grâce au modèle open source de Facebook (Llama)

------------------------------------------------------------------------

[![](figure/nvidia_shovel.png){fig-align="center" width="600"}](https://www.google.com/url?sa=i&url=https%3A%2F%2Fanalyticsindiamag.com%2Fai-origins-evolution%2Fnvidia-sells-gpus-not-shovels%2F&psig=AOvVaw0XSt0BMsfWUhD0hwaVSQFL&ust=1728784302931000&source=images&cd=vfe&opi=89978449&ved=0CBcQjhxqFwoTCODf2Mndh4kDFQAAAAAdAAAAABAR)

## La bulle financière de l'IA

### Surinvestissement dans l'IA :

-   L'afflux rapide des **investissements dans l'IA** a fait craindre une bulle financière.
-   Les **institutions financières** investissent massivement dans les technologies de l'IA pour gagner en efficacité, mais il existe des risques.

### Risque de bulle :

-   À l'instar de la **bulle Internet** du début des années 2000, de nombreux projets d'IA sont surestimés et ne s'appuient pas sur des modèles commerciaux réels et durables.
-   Les **gains à court terme** de l'IA pourraient conduire à un effondrement si la technologie ne donne pas les résultats escomptés, ce qui aurait un impact sur les **marchés financiers** et les économies.

## Autres limites

## Limites des LLM

-   **Coûts** : Ces modèles ont besoin d'une [grande puissance de calcule]{.underline} pour les entraîner et les utiliser. Seules [des grandes entreprises]{.underline} peuvent se lancer dans leur création.

    -   Cependant, il existe des projets [open-source]{.underline} et [locaux]{.underline} mais qui ne sont pas aussi puissants que des modèles comme ChatGPT ou Claud (Llama, Mixtral, Phi, etc.)

-   **Développement** : Jusqu'à présent, la principale stratégie employée a simplement consisté à [augmenter la taille des modèles, des données et des infrastructures]{.underline}, sans apporter de changements majeurs au modèle lui-même.

## Limites des LLM

-   **Hallucination et précision** : Ces modèles ont également tendance à [répondre avec beaucoup d'assurance des choses fausses]{.underline} ou [qui n'ont rien à voir avec le sujet]{.underline}. Bien que cela puisse sembler être un bug ou quelque chose d'inattendu, ce n'est en fait pas surprenant : [ces modèles ont été entraînés à prédire le mot suivant, et non à répondre correctement]{.underline}.

    -   Il existe également un [biais de confiance]{.underline}, car lors de la [phase d'annotation humaine]{.underline}, les réponses plus sûres ont tendance à être plus appréciées (biais cognitif).

## Limites des LLM

-   **Sécurité** : Comme les modèles ne sont pas codés à la main avec des règles, [leur comportement ne peut être prédit]{.underline}, d'où la nécessité d'une [validation humaine]{.underline} pour réduire les réponses problématiques (censure). Cependant, il est [impossible de prévoir tous les cas]{.underline} et, très souvent, des personnes trouvent un moyen de détourner les modèles.

    -   Solution: [données de meilleures qualités]{.underline} (garbage-in, garbage-out)

[![](figure/chatgpt_detournement.PNG){fig-align="center"}](https://www.zdnet.fr/actualites/chatgpt-est-deja-detourne-pour-ecrire-des-logiciels-malveillants-39952280.htm)

## Limites des LLM

-   **Mise à jour** : Leurs connaissances sont figées dans le temps après la formation. Il existe cependant des moyens de les mettre à jour en les connectant à Internet ou en basant leurs réponses sur des documents spécifiques (RAG).

[![](figure/rag.png){fig-align="center" width="783"}](https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.linkedin.com%2Fpulse%2Fgenerative-ai-augmented-recovery-generation-rag-its-data-sampaio-oll2f&psig=AOvVaw2dVAa8O8qI33G9qzT973_8&ust=1728769104820000&source=images&cd=vfe&opi=89978449&ved=0CBcQjhxqFwoTCNj0poGlh4kDFQAAAAAdAAAAABAE)

## Limites des LLM

**Autres** :

-   Copyright (contenu volé)

-   Manque de mémoire à long terme (basé sur leur "token window")

-   Biais culturels

-   Risque de confidentialité (OpenAI stock et utilisent les conversations)

# Alternatives Viables ? (35 minutes)

## Introduction : Pourquoi explorer les alternatives à ChatGPT?

-   Bien que **ChatGPT** soit un modèle d'IA populaire, plusieurs autres alternatives offrent des caractéristiques et des améliorations uniques. De plus, les problèmes suivant doivent être mentionnés:
    -   **Confidentialité** : Stocke les conversations et les utilise pour former le modèle.
    -   **Utilisation** : Généraliste, ne convient pas à toutes les utilisations
    -   **Droit d'auteur** : a volé de nombreux contenus en ligne
    
## L'univers des options

- Copilot
- Gemini
- Claude
- DeepSeek
- Perplexity AI

## 1) Copilot (anciennement Bing AI)

<https://www.bing.com/chat>

1.  **Information en temps réel** : Contrairement à ChatGPT, Copilot est connecté à Internet, fournissant des données à jour et des événements actuels.
2.  **Intégration de la recherche sur le web** : Copilot peut effectuer des recherches sur le web et résumer les résultats.
3.  **Génération d'images** : Alimenté par **DALL-E**, il peut générer des images à partir d'invites textuelles.
4.  **Traitement des données visuelles** : Les utilisateurs peuvent télécharger des images et recevoir des informations ou des analyses à leur sujet.

## 2) Gemini

<https://gemini.google.com/app>

1.  **Capacités multimodales** : Gemini gère le texte, les images, l'audio et la vidéo​.
2.  **Meilleures performances** : Surpasse le GPT-4 dans les tests de référence liés à la compréhension et au raisonnement linguistiques multitâches.
3.  **Capacités de codage avancées** : Excelle dans les tâches liées au code, fournissant des résultats plus précis.

## 3) Claude

<https://claude.ai/login?returnTo=%2F%3F>

1.  **Fenêtre contextuelle plus longue** : Claude peut mémoriser et traiter des conversations beaucoup plus longues (jusqu'à 100 000 mots).
2.  **Forme formation éthique** : Conçu pour gérer les problèmes éthiques et refuser les demandes inappropriées.
3.  **Persistance à la tâche** : Meilleure capacité à suivre des instructions complexes en plusieurs étapes.

## 4) DeepSeek

1. **Coût réduit** : Le développement de DeepSeek a coûté environ 5,58 millions de dollars, soit 20 à 40 fois moins que ChatGPT15. Cette efficacité économique se traduit par des tarifs plus abordables pour les utilisateurs.
2. **Efficacité énergétique** : DeepSeek nécessite 10 fois moins de puissance de calcul que ChatGPT, ce qui réduit considérablement son empreinte écologique
3. **Performances comparables** : Malgré son coût réduit, DeepSeek rivalise avec les modèles propriétaires les plus performants en termes de capacités de traitement du langage naturel

## 5) Perplexity AI

<https://www.perplexity.ai/>

1.  **Information en temps réel** : Fournit des données en temps réel en effectuant des recherches sur le web.
2.  **Multiples modèles** : Utilise GPT-4, Claude 3 et Gemini Pro, ce qui permet aux utilisateurs de sélectionner différents modèles pour diverses tâches.
3.  **Citations de sources** : Fournit des citations pour toutes ses informations, améliorant ainsi la transparence.

## Bonus (1)

Il y a une IA pour ça:

[There is an AI for that](https://theresanaiforthat.com/)

- liste de nombreuses IA
- possiblité de filtrer
- À jour

## Bonus (2)

Autres que j'utilise:

- [Quillbot](https://quillbot.com/)
- [Elicit](https://elicit.com/)

## Pour la vie privée

- Duckduckgo AI
- Huggingface space
- LMStudio
- Ollama

## duckduckgo AI

<https://duckduckgo.com/>

1. **Accessible**: Gratuit et il suffit d'aller sur le lien
2. **Privé**: Pas besoin de compte
3. **Puissant**: Les modèles disponibles sont GPT-4o mini, Lama3.3 70B, Claude 3 Haiku, o3-mini, Mistral 8x7B

## Huggingface space

<https://huggingface.co/spaces>

1.  **Déploiement facile** : Permet aux utilisateurs de créer et de partager rapidement des démos d'IA.
2.  **Intégration** : Accès direct à l'écosystème du modèle Hugging Face.
3.  **Collaboration** : Offre des outils de contrôle de version et de collaboration pour les équipes.

## LMStudio :

<https://lmstudio.ai/>

-   **Exécution locale de modèles** : Permet aux utilisateurs d'exécuter des modèles d'IA localement sans dépendre de services en ligne.
-   **Convivialité** : Fournit une interface graphique pour la gestion des modèles.
-   **Confidentialité** : Toutes les données sont conservées au niveau local, ce qui garantit une sécurité et une confidentialité accrues.

## Ollama :

<https://ollama.com/>

-   **Exécution locale de modèles** : Permet aux utilisateurs d'exécuter des modèles d'IA localement sans dépendre de services en ligne.
-   **Confidentialité** : Toutes les données sont conservées au niveau local, ce qui garantit une sécurité et une confidentialité accrues.
-   **Interface de ligne de commande** : Fournit un outil simple et léger pour exécuter des modèles localement​.
-   **Personnalisation** : Permet aux utilisateurs de créer et de modifier des modèles personnalisés pour des besoins spécifiques.

## Résumé : choisir la bonne alternative

-   **Copilot** excelle dans l'information en temps réel et l'intégration web.
-   **Gemini** offre de solides capacités multimodales et une expertise en matière de codage.
-   **Claude** offre des considérations éthiques et une mémoire plus longue.
-   **Perplexité** associe des informations en temps réel à des citations de sources.
-   **Hugging Face Spaces**, **Duckduckgo AI**, **LMStudio**, et **Ollama** offrent des solutions d'IA flexibles et locales pour les utilisateurs soucieux de leur vie privée.

## Modèles locaux solution parfaite?

**Avantages:**

- Confidentialité
- Impact environmental marginal

**Désavantages:**

- Moins performant que les plus gros modèles (OpenAI, Anthropic, etc.)
- Demande plus d'apprentissage

## La puissance des SLM

**SLM**: Small Language Models = modèles locaux

![](figure/model_size.png)

## La puissance des SLM

Modèles de plus en plus gros...

![](figure/gpt_size.png)

## Les petits modèles deviennent de plus en plus intelligent

- Les modèles modernes de la taille de GPT2 (1.5B) sont beaucoups plus intelligents
- On fait plus avec moins (ex. DeepSeek)

![](figure/slm_performance.jpg)

## Compariason

![](figure/llm_vs_slm.webp)

# Ollama et compagnie (20 minutes)

## Comment marche un modèle local?

Comme un grand modèle...

## Que sont les large language models (LLM) ?

-   Les **LLM** sont un type d'intelligence artificielle (IA) capable de [comprendre]{.underline} et de [générer du texte]{.underline}.
-   Ils permettent à des outils comme ChatGPT de créer des réponses, de compléter des phrases et même de tenir des conversations.

### Comment les LLMs génèrent du texte ? :

1.  Les LLM [prédisent la suite d'une phrase]{.underline}.
2.  Ils sont formés en utilisant de vastes [quantités de données]{.underline} textuelles provenant de livres, de sites Web, etc.
3.  Ils fonctionnent en [générant un mot à la fois]{.underline}, sur la base des mots précédents.

## Comment fonctionnent les LLM?

Les LLM sont basés sur le modèle de **transformer**, qui se compose de :

-   **Encoder** : [Apprend]{.underline} à partir du texte d'entrée.

-   **Décodeur** : [Prédit]{.underline} le mot suivant en utilisant les données encodées.

**Création du premier GPT** (**Generative Pre-trained Transformer)**

-   Ces modèles **transformer** servaient [de base à la traduction]{.underline} mais ont vu leur usage s'élargir à la génération de texte

-   Au lieu de leur donner un texte d'une langue A à traduire dans la langue B, on utilise uniquement le **décodeur** pour [prédire le prochain mot]{.underline}

## Comment un LLM apprend-il ?

En tant que modèle de machine learning, le modèle a besoin d'apprendre en premier lieu.

**1 - Phase d'entraînement** (avant la sortie du modèle) :

-   Le modèle lit et analyse de [grandes quantités de texte]{.underline}.
-   Il apprend des données [la façon dont les mots sont utilisés ensemble]{.underline}, tout comme les humains apprennent en lisant des livres ou en écoutant des conversations.

![](figure/ml_rule.png){fig-align="center"}

------------------------------------------------------------------------

**2 - Phase d'annotation/censure**:

-   Comme les [données]{.underline} stockées ne sont [pas filtrées]{.underline}, il y a du [contenu problématique]{.underline} ou qui sont tout simplement [inacceptable]{.underline}.
-   Pour éviter que le modèle ne produise quoi que ce soit, nous avons besoin [d'humains pour valider les réponses et guider le modèle]{.underline}.

[![](figure/human_feedback.jpg){fig-align="center" width="479"}](https://time.com/6247678/openai-chatgpt-kenya-workers/)

------------------------------------------------------------------------

**3 - Phase de prédiction** (après l’entraînement) :

-   Après l'entraînement, le modèle [prédit le mot suivant]{.underline} dans une phrase [en se basant sur les mots qui le précèdent]{.underline}.

[![](gif/word_prediction.gif){fig-align="center" width="800"}](https://www.youtube.com/watch?v=wjZofJX0v4M)

------------------------------------------------------------------------

## Comment les LLM génèrent-ils du texte ?

### Exemple : Rédaction d'une histoire

1.  **Entrée** : L'utilisateur commence par une phrase : "Il était une fois..."
2.  **Prédiction** : Le LLM prédit le mot suivant dans l'histoire en [choisissant le mot le plus probable]{.underline} sur la base de ce qu'il a appris.
3.  **Répétition** : Il continue à prédire et à ajouter des mots jusqu'à ce que l'histoire soit complète.

[![](gif/word_prediction.gif){fig-align="center" width="533"}](https://www.youtube.com/watch?v=wjZofJX0v4M)

------------------------------------------------------------------------

## La tokenisation : Découpage du texte en morceaux

-   Les LLM ne traitent pas des phrases entières en une seule fois. Au lieu de cela, ils [décomposent le texte en plus petits morceaux]{.underline} appelés **tokens**.
-   Les tokens peuvent être: des mots entiers, [des parties de mots]{.underline} ou des signes de ponctuation

[![](gif/tokens.gif){fig-align="center" width="621"}](https://www.youtube.com/watch?v=wjZofJX0v4M)

------------------------------------------------------------------------

## Embedding : Comprendre le sens des nombres

-   Chaque mot est converti en **vecteur**, qui est une [liste de nombres représentant la signification du mot]{.underline}.
-   Les mots ayant des [significations similaires]{.underline} (par exemple, "chat" et "chien") auront des [vecteurs proches]{.underline} les uns des autres dans cet espace.
-   Ces vecteurs aident le LLM à comprendre le [contexte]{.underline} et la [relation entre les mots]{.underline}.

[![](gif/embedding.gif){fig-align="center" width="533"}](https://www.youtube.com/watch?v=wjZofJX0v4M)

------------------------------------------------------------------------

## Attention : Comment les LLM comprennent le contexte

-   L'**attention** est le mécanisme clé qui aide les LLM à [se concentrer sur les mots importants]{.underline} d'une phrase.
-   Par exemple, dans la phrase "Le chat s'est assis sur le tapis", l'attention aide le modèle à savoir que "chat" et "assis" sont liés.
-   Cela permet au modèle de générer un texte [plus précis]{.underline} et [plus pertinent]{.underline}.

[![](gif/embedding_attention.gif){fig-align="center"}](https://www.youtube.com/watch?v=wjZofJX0v4M)

------------------------------------------------------------------------

## Comment un LLM utilise-t-il l'attention ?

1.  Il examine tous les [tokens]{.underline} d'une phrase.
2.  Il décide quels mots sont les [plus importants]{.underline} pour prédire le mot suivant.
3.  Il [actualise sa compréhension]{.underline} de chaque mot en fonction du [contexte]{.underline} des autres mots.

[![](gif/weight_update.gif){fig-align="center"}](https://www.youtube.com/watch?v=wjZofJX0v4M)

------------------------------------------------------------------------

## Le résultat final : Choix du mot suivant

-   Après avoir traité les tokens et appliqué l'attention, le LLM produit une [liste de mots suivants possibles]{.underline}, chacun avec une [probabilité]{.underline}.
-   [Le mot ayant la probabilité la plus élevée est choisi]{.underline}, et ce processus se répète pour générer plus de texte.

[![](gif/word_prediction_2.gif){fig-align="center" width="799"}](https://www.youtube.com/watch?v=wjZofJX0v4M)

## Pourquoi les LLM sont-ils si puissants ?

1.  **Échelle** : Les LLM comme le GPT-3 ont été entraînés sur de [grandes quantités de texte]{.underline} (livre, forums, internet, etc.), ce qui leur donne une [compréhension]{.underline} profonde du langage.
2.  **Adaptabilité** : Ils peuvent gérer une [grande variété de tâches]{.underline}, en partant de la réponse à des questions jusqu'à la rédaction d'histoires ou le codage.
3.  **Créativité** : En prédisant un mot à la fois, les LLM peuvent générer des réponses [étonnamment cohérentes et créatives]{.underline}.

## Ollama, LMStudio, llama.cpp, etc.

- **Ollama** est idéal pour ceux qui recherchent une solution simple à utiliser avec un support multiplateforme, mais il est limité par la nécessité d'un GPU dédié.
- **LM Studio** offre une excellente expérience utilisateur et fonctionne hors ligne, mais il est gourmand en ressources matérielles.
- **llama.cpp** est particulièrement adapté aux systèmes légers ou sans GPU grâce à son optimisation CPU, mais il peut nécessiter des compétences techniques avancées.

## Pourquoi Ollama?

- Facile d'installation
- Peut s'intégrer par défaut à de nombreux outils (Obsidian, Copilot, etc.)
- A un très grand [écosystème](https://github.com/ollama/ollama)

## GPU et VRAM?

- Le GPU (ou carte graphique) et la VRAM sont indispensables pour l'utilisation des modèles de langage (LLM).

- **Caractéristiques du GPU :**
   - Spécialisé pour les calculs en parallèle.
   - Adapté au traitement des réseaux neuronaux profonds.
   
- **Rôle et importance de la VRAM :**
   - Mémoire spécifique pour le stockage rapide de données graphiques.
   - Cruciale pour stocker les poids des neurones et les données intermédiaires dans les LLM.
   
**Pour connaître la puissance de son ordinateur pour les llms, il faut vérifier la VRAM**
   
## Vérifier sa VRAM

- [Windows](https://www.howtogeek.com/797643/how-to-find-vram-on-windows-11/)

- [Mac](https://www.mackiev.com/techsupport/ht_vram.html)

- [Linux](https://www.lecoindunet.com/comment-verifier-la-ram-sur-linux)

# Ollama pratique (90 minutes)

## Terminal

- On utilise de base un terminal avec Ollama
- Il existe des interfaces utilisateurs plus simple
- Il est improtant de connaitre les commande de base

![](figure/terminal.png)

## COmmandes de base

Aide

```shell
ollama help
```
Équivalent

```shell
ollama
```
Liste des modèles

```shell
ollama list
```

Information sur un modèle

```shell
ollama show qwen2.5:3b
```

Télécharger un nouveau modèle

```shell
ollama pull bge-m3
```

## Exercie

En attendant le que téléchargement soit fini. Vous pouvez tester les alternatives que nous avons présenté plus tôt:

- [There is an AI for that](https://theresanaiforthat.com/)
- [Duckduckgo AI](https://duckduckgo.com/)
- [HuggingFace Space](https://huggingface.co/spaces)

Suite: lancer un modèle

```shell
ollama run qwen2.5:3b
```

## Dans une conversation

Liste des commandes

```shell
/?
```

Infos sur le modèle

```shell
/show info
```

Effacer le contexte

```shell
/clear
```

Quitter la conversation

```shell
/bye
```

## Exercice

- Tester le modèle pour différente tâches
- Chercher d'autres modèle sur la page des modèles de [ollama](https://ollama.com/search)
- Durant le téléchargement vous pouvez aller tester les autres alternatives:
  - [There is an AI for that](https://theresanaiforthat.com/)
  - [Duckduckgo AI](https://duckduckgo.com/)
  - [HuggingFace Space](https://huggingface.co/spaces)
- Tester les nouveaux modèles téléchargés

Exemple de tâche: question de culture générale, question mathématique, synonyme, formulation, etc.

## Votre avis sur l'expérience d'utilisation?

## GUI: PageAssist

Utilisons une interface utilisateur: Page Assist

- [Chrome](https://chromewebstore.google.com/detail/page-assist-a-web-ui-for/jfgfiigpkhlkbnfnbobbkinehhfdhndo)
- [FireFox](https://addons.mozilla.org/en-US/firefox/addon/page-assist/?utm_source=addons.mozilla.org&utm_medium=referral&utm_content=search)

*Le lien chrome fonctionne aussi pour: Brave, Vivaldi, Edge, Opera*

## Choisir ses modèle(s)

## RAG

## Prompting